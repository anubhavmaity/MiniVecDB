# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_ivf_index.ipynb.

# %% auto 0
__all__ = ['func_map', 'vers', 'euclidean', 'neg_dot', 'run_kmeans', 'build_index', 'IVFIndex']

# %% ../nbs/01_ivf_index.ipynb 2
import numpy as np 
from typing import List, Dict, Tuple, Any
from fastkmeans import FastKMeans
from collections import defaultdict
import fastcore.all as fc

from .vector_storage import VectorStorage
from . import gen_emb

# %% ../nbs/01_ivf_index.ipynb 4
def vers(a, b): return 1.0 - np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8) # 1 - cosine

# %% ../nbs/01_ivf_index.ipynb 6
def euclidean(a, b): return np.linalg.norm(a-b)

# %% ../nbs/01_ivf_index.ipynb 8
def neg_dot(a, b): return -np.dot(a, b) # negative dot

# %% ../nbs/01_ivf_index.ipynb 9
func_map = {
    'cosine': vers,
    'euclidean': euclidean,
    'dot': neg_dot
}

# %% ../nbs/01_ivf_index.ipynb 13
def run_kmeans(data):
    kmeans = FastKMeans(d=data.shape[1], k=data.shape[0] // 10 + 1,  gpu=False)
    preds = kmeans.fit_predict(data)
    return kmeans.centroids, preds

# %% ../nbs/01_ivf_index.ipynb 16
def build_index(vs):
    ids, vectors = zip(*[(id, vector) for id, vector, _ in vs.get_all()])
    centroids, preds = run_kmeans(np.array(vectors))
    cluster_ids_map = defaultdict(list)
    id_cluster_map = {}
    for id, cluster_id in zip(ids, preds):
        cluster_ids_map[cluster_id.item()].append(id)
        id_cluster_map[id] = cluster_id.item()
    return cluster_ids_map, id_cluster_map, centroids

# %% ../nbs/01_ivf_index.ipynb 21
class IVFIndex:
    def __init__(self, storage: VectorStorage, nprobe= 10, distance_fn = "cosine"):
        fc.store_attr()
        self.nprobe = nprobe
        self.distance_fn = distance_fn
        self.is_built = False
        self.dist_func = func_map[distance_fn]
    
    def build(self):
        all_data = self.storage.get_all()
        if not all_data: raise ValueError("Storage is empty, cannot build index")

        self.inverted_lists, self.assignments, self.centroids = build_index(self.storage)
        
        self.is_built = True
        
        sizes = [len(lst) for lst in self.inverted_lists.values()]
        print(f"Average list size: {sum(sizes)/len(sizes):.1f}, Max: {max(sizes)}")
    
    def search(self, query_vector, k = 5):
        if not self.is_built: raise ValueError("Index not built. Call build() first.")
    
        centroid_distances = fc.L(self.centroids.tolist()).enumerate().map(lambda o: (vers(o[1], query_vector).item(), o[0]))
        centroid_distances.sort()

        candidate_ids = centroid_distances[:self.nprobe].itemgot(1).map(lambda o: self.inverted_lists[o]).concat()
        
        if len(candidate_ids) < k:
            for _, cluster_id in centroid_distances[self.nprobe:]:
                candidate_ids.extend(self.inverted_lists[cluster_id])
                if len(candidate_ids) >= k * 2:
                    break

        results = candidate_ids.enumerate().map(lambda o: self.storage.get(o[1])).sorted(key=lambda o: self.dist_func(query_vector, o[0]))
        return results[:k]
    
    
    def add_vectors_bulk(self, vectors, metadata_list):
        ids = fc.L(vectors, metadata_list).zip(lambda o: self.storage.add(o[0], o[1]))
        self.build()
        return ids
    
    def get_stats(self):
        if not self.is_built: return {"built": False}
        
        sizes = [len(lst) for lst in self.inverted_lists.values()]
        return {
            "built": True,
            "n_clusters": len(self.centroids),
            "n_vectors": sum(sizes),
            "avg_cluster_size": sum(sizes) / len(sizes),
            "min_cluster_size": min(sizes),
            "max_cluster_size": max(sizes),
            "empty_clusters": sizes.count(0),
            "nprobe": self.nprobe
        }

