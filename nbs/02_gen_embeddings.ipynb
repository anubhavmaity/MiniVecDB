{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d58ee8-48b9-453e-ad00-4ed4617b2463",
   "metadata": {},
   "source": [
    "# Generating Embeddings with Gemini\n",
    "\n",
    "This notebook sets up our connection to Google's Gemini API for creating text embeddings.\n",
    "\n",
    "## What are Embeddings?\n",
    "\n",
    "Embeddings are the magic that makes vector databases work. They convert text (or other data) into lists of numbers that capture meaning.\n",
    "\n",
    "For example, these phrases would have similar embeddings:\n",
    "- \"I love dogs\"\n",
    "- \"Puppies are my favorite\"\n",
    "\n",
    "While these would have very different embeddings:\n",
    "- \"I love dogs\"\n",
    "- \"Interest rates are rising\"\n",
    "\n",
    "Embeddings capture semantic relationships - words and phrases with similar meanings have similar vectors, even if they don't share any keywords.\n",
    "\n",
    "## Why Gemini?\n",
    "\n",
    "We're using Google's Gemini API to create high-quality embeddings:\n",
    "- 768-dimensional vectors capture rich semantic information\n",
    "- Optimized for finding similar content\n",
    "- State-of-the-art performance for search and recommendation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38963ea-b441-4993-8462-d8147d7d9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp gen_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4cd81-bd75-4e34-a1bd-5518077f1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0039c1-b228-47d1-b0d4-14c76278b619",
   "metadata": {},
   "source": [
    "## Setting Up the Client\n",
    "\n",
    "First, we import the necessary libraries and set up our client.\n",
    "\n",
    "Make sure you have an API key for Gemini stored in your environment variables as 'GEMINI_API_KEY'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d83f0-b005-4aa5-bea9-31de5d20e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "def get_embedding(contents, model=\"text-embedding-004\"):\n",
    "    return np.array(client.models.embed_content(model=model, contents=contents, config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")).embeddings[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74cde5e-1cb1-4c56-85a2-b76197ca4f0e",
   "metadata": {},
   "source": [
    "## The Embedding Function\n",
    "\n",
    "Our `get_embedding` function:\n",
    "1. Takes text content as input\n",
    "2. Sends it to Gemini's embedding API\n",
    "3. Gets back a 768-dimensional vector\n",
    "4. Returns it as a numpy array\n",
    "\n",
    "We're using the \"SEMANTIC_SIMILARITY\" task type, which optimizes the embeddings for finding related content.\n",
    "\n",
    "The resulting vectors can be compared using cosine similarity or other distance metrics to find similar content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aafd7cc-de6b-4d64-9e7e-c1c562062a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding(\"Dow Jumps 1,000 Points Tuesday as Markets Rebound from Recent Losses\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a73299-c096-4632-aab8-fd0d3ba71606",
   "metadata": {},
   "source": [
    "## Testing Our Function\n",
    "\n",
    "Let's test with a simple headline. The resulting embedding is a 768-dimensional vector.\n",
    "\n",
    "Each dimension in this vector represents some aspect of the text's meaning, learned by the model during training. The specific meaning of each dimension isn't interpretable by humans, but the overall pattern of values captures the semantic content.\n",
    "\n",
    "We can use these embeddings to:\n",
    "- Find similar content\n",
    "- Group related items\n",
    "- Build recommendation systems\n",
    "- Enable semantic search\n",
    "\n",
    "Next, see 03_headline_embeddings.ipynb for a complete example of using these embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510180d-7f51-4f21-8ee6-24a609a9dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052c0dd-a9f3-417a-86ae-6b8552b5f49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minivecdb",
   "language": "python",
   "name": "minivecdb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
