{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f03a335-f60d-4e1d-8572-3158b9e08a0c",
   "metadata": {},
   "source": [
    "# IVF Index: Making Vector Search Fast\n",
    "\n",
    "This notebook implements the Inverted File (IVF) Index algorithm for efficient approximate nearest neighbor search.\n",
    "\n",
    "## The Challenge: Searching Through Millions of Vectors\n",
    "\n",
    "Vector databases are great for finding similar content, but they face a common problem: as your collection grows, searching gets slower because you need to compare your query against EVERY vector.\n",
    "\n",
    "Imagine searching through a million vectors - that's a lot of comparisons!\n",
    "\n",
    "## The Solution: Clustering Vectors\n",
    "\n",
    "IVF Index solves this by grouping similar vectors into clusters:\n",
    "\n",
    "1. We divide our vectors into groups (clusters) of similar vectors\n",
    "2. For each cluster, we choose a representative vector (centroid)\n",
    "3. When searching, we first find the nearest centroids\n",
    "4. Then we only search within those few closest clusters\n",
    "\n",
    "It's like asking \"Which section of the library should I look in?\" before searching through every book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8be53e-24dc-447f-a8b6-321ae48f1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ivf_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c03efd0-5c6e-4088-83f2-cc12844bf887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import numpy as np \n",
    "from typing import List, Dict, Tuple, Any\n",
    "from fastkmeans import FastKMeans\n",
    "from collections import defaultdict\n",
    "import fastcore.all as fc\n",
    "\n",
    "from minivecdb.vector_storage import VectorStorage\n",
    "from minivecdb import gen_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a7841-741b-457b-96fe-4b8ef28e1ca8",
   "metadata": {},
   "source": [
    "## Distance Functions: How We Measure Similarity\n",
    "\n",
    "To find similar vectors, we need ways to measure how \"close\" or \"far apart\" they are. Different distance functions capture different types of similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a674342-26bc-42d8-8ef7-d9874fac7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def vers(a, b): return 1.0 - np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8) # 1 - cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b638631-09fb-41a3-beb5-22dd7d35128f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2928932259563096),\n",
       " np.float64(0.2928932259563096),\n",
       " np.float64(1.9999999857142858))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.array([1, 0, 0])       \n",
    "v2 = np.array([0, 1, 0])\n",
    "v3 = np.array([-0.5, -0.5, 0])\n",
    "\n",
    "query = np.array([0.7, 0.7, 0]) \n",
    "vers(v1, query), vers(v2, query), vers(v3, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0abc4c7d-ccc1-4c0d-b167-6cbeca3a08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def euclidean(a, b): return np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7094a748-7a04-487b-8d13-5f5dde17aa9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7615773105863908),\n",
       " np.float64(0.7615773105863908),\n",
       " np.float64(1.697056274847714))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean(v1, query), euclidean(v2, query), euclidean(v3, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c9b7c6-9af2-40f8-b264-783eeec057d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def neg_dot(a, b): return -np.dot(a, b) # negative dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd5592e-66c2-4e2a-8b7e-a19880dc3150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "func_map = {\n",
    "    'cosine': vers,\n",
    "    'euclidean': euclidean,\n",
    "    'dot': neg_dot\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "649db3d9-dc74-4426-acde-5da575d1dbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.7), np.float64(-0.7), np.float64(0.7))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_dot(v1, query), neg_dot(v2, query), neg_dot(v3, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae46c88-5ea1-414a-9705-1065ea3c1c87",
   "metadata": {},
   "source": [
    "Different distance functions are better for different tasks:\n",
    "\n",
    "- **Cosine**: Best for semantic similarity when vector size doesn't matter\n",
    "- **Euclidean**: Best when absolute positions in vector space matter\n",
    "- **Dot Product**: Good for normalized vectors (all same length)\n",
    "\n",
    "Our examples show how these measures rank similarity differently for the same vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d424f0-ef09-42d8-b0fa-6c1c7d345ffa",
   "metadata": {},
   "source": [
    "## Understanding K-means Clustering\n",
    "K-means clustering is an algorithm that groups similar data points by iteratively assigning points to the nearest of K centers, then updating those centers based on the assigned points. The FastKMeans library we're using optimizes this process through efficient distance calculations and smarter initialization, which helps our IVF Index group similar vectors into clusters – allowing us to search just a few promising clusters rather than the entire database, dramatically improving search speed as our collection grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280d8755-2f80-4044-a77e-ecbaff855d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def run_kmeans(data):\n",
    "    kmeans = FastKMeans(d=data.shape[1], k=data.shape[0] // 10 + 1,  gpu=False)\n",
    "    preds = kmeans.fit_predict(data)\n",
    "    return kmeans.centroids, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ee2a80-1be4-424c-826c-1698e9d2b9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 768), (20,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids, preds = run_kmeans(np.random.randn(20, 768))\n",
    "centroids.shape, preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce917b90-77a5-43b2-b1fc-d505405c2956",
   "metadata": {},
   "source": [
    "## Building the Index\n",
    "\n",
    "The key to the IVF approach is dividing vectors into clusters. We'll use K-means clustering, which:\n",
    "\n",
    "1. Randomly selects initial cluster centers\n",
    "2. Assigns each vector to the nearest center\n",
    "3. Recalculates centers based on assigned vectors\n",
    "4. Repeats until convergence\n",
    "\n",
    "Our `build_index` function handles this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8059c3ee-f928-47d3-8f85-cd65931fdcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def build_index(vs):\n",
    "    ids, vectors = zip(*[(id, vector) for id, vector, _ in vs.get_all()])\n",
    "    centroids, preds = run_kmeans(np.array(vectors))\n",
    "    cluster_ids_map = defaultdict(list)\n",
    "    id_cluster_map = {}\n",
    "    for id, cluster_id in zip(ids, preds):\n",
    "        cluster_ids_map[cluster_id.item()].append(id)\n",
    "        id_cluster_map[id] = cluster_id.item()\n",
    "    return cluster_ids_map, id_cluster_map, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf4ea34-498c-4f91-8878-cfaff08a5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VectorStorage.load('data/headline_embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8263e515-7a26-4375-be5d-d74e0eaffbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids_map, id_cluster_map, centroids = build_index(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff23ba-f19f-4cc3-94c6-f36c77c2aee6",
   "metadata": {},
   "source": [
    "## The IVFIndex Class\n",
    "\n",
    "Now we'll build a complete index that:\n",
    "1. Stores vectors and cluster assignments\n",
    "2. Lets us search efficiently\n",
    "3. Can add new vectors\n",
    "\n",
    "The key parameters are:\n",
    "- `nprobe`: How many closest clusters to search (higher = more accurate but slower)\n",
    "- `distance_fn`: Which distance metric to use (cosine, euclidean, or dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31cd6b-fa69-4eb2-927a-8d6200f9f4a5",
   "metadata": {},
   "source": [
    "## Using the Index\n",
    "\n",
    "Let's try our index on a real dataset of headline embeddings:\n",
    "\n",
    "1. Then we build the index from our storage(clustering the vectors)\n",
    "2. Finally, we search for similar headlines\n",
    "\n",
    "The stats show us how vectors are distributed across clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f181aa4-38f8-40c3-b958-ca1846f4e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class IVFIndex:\n",
    "    def __init__(self, storage: VectorStorage, nprobe= 10, distance_fn = \"cosine\"):\n",
    "        fc.store_attr()\n",
    "        self.nprobe = nprobe\n",
    "        self.distance_fn = distance_fn\n",
    "        self.is_built = False\n",
    "        self.dist_func = func_map[distance_fn]\n",
    "    \n",
    "    def build(self):\n",
    "        all_data = self.storage.get_all()\n",
    "        if not all_data: raise ValueError(\"Storage is empty, cannot build index\")\n",
    "\n",
    "        self.inverted_lists, self.assignments, self.centroids = build_index(self.storage)\n",
    "        \n",
    "        self.is_built = True\n",
    "        \n",
    "        sizes = [len(lst) for lst in self.inverted_lists.values()]\n",
    "        print(f\"Average list size: {sum(sizes)/len(sizes):.1f}, Max: {max(sizes)}\")\n",
    "    \n",
    "    def search(self, query_vector, k = 5):\n",
    "        if not self.is_built: raise ValueError(\"Index not built. Call build() first.\")\n",
    "    \n",
    "        centroid_distances = fc.L(self.centroids.tolist()).enumerate().map(lambda o: (vers(o[1], query_vector).item(), o[0]))\n",
    "        centroid_distances.sort()\n",
    "\n",
    "        candidate_ids = centroid_distances[:self.nprobe].itemgot(1).map(lambda o: self.inverted_lists[o]).concat()\n",
    "        \n",
    "        if len(candidate_ids) < k:\n",
    "            for _, cluster_id in centroid_distances[self.nprobe:]:\n",
    "                candidate_ids.extend(self.inverted_lists[cluster_id])\n",
    "                if len(candidate_ids) >= k * 2:\n",
    "                    break\n",
    "\n",
    "        results = candidate_ids.enumerate().map(lambda o: self.storage.get(o[1])).sorted(key=lambda o: self.dist_func(query_vector, o[0]))\n",
    "        return results[:k]\n",
    "    \n",
    "    \n",
    "    def add_vectors_bulk(self, vectors, metadata_list):\n",
    "        ids = fc.L(vectors, metadata_list).zip(lambda o: self.storage.add(o[0], o[1]))\n",
    "        self.build()\n",
    "        return ids\n",
    "    \n",
    "    def get_stats(self):\n",
    "        if not self.is_built: return {\"built\": False}\n",
    "        \n",
    "        sizes = [len(lst) for lst in self.inverted_lists.values()]\n",
    "        return {\n",
    "            \"built\": True,\n",
    "            \"n_clusters\": len(self.centroids),\n",
    "            \"n_vectors\": sum(sizes),\n",
    "            \"avg_cluster_size\": sum(sizes) / len(sizes),\n",
    "            \"min_cluster_size\": min(sizes),\n",
    "            \"max_cluster_size\": max(sizes),\n",
    "            \"empty_clusters\": sizes.count(0),\n",
    "            \"nprobe\": self.nprobe\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fb7e335-f074-4337-a361-0207e3e6ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average list size: 9.8, Max: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'built': True,\n",
       " 'n_clusters': 39,\n",
       " 'n_vectors': 383,\n",
       " 'avg_cluster_size': 9.820512820512821,\n",
       " 'min_cluster_size': 1,\n",
       " 'max_cluster_size': 28,\n",
       " 'empty_clusters': 0,\n",
       " 'nprobe': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = IVFIndex(vs, nprobe=10, distance_fn=\"cosine\")\n",
    "index.build()\n",
    "index.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6474224-9c05-47e9-9a5d-840f9e21b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [{'headline': 'Marathon Runner Breaks World Record', 'genre': 'Sports'},{'headline': 'Sprinter Breaks National Record', 'genre': 'Sports'},{'headline': 'Climber Sets New Speed Record', 'genre': 'Sports'},{'headline': 'City Hosts Annual Marathon', 'genre': 'Local News'},{'headline': 'Track Star Qualifies for World Championships', 'genre': 'Sports'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"John Korir Claims Victory in Boston Marathon as Evans Lokedi Breaks Women's Course Record\"\n",
    "query_vector = gen_emb.get_embedding(query)\n",
    "results = index.search(query_vector, k=5)\n",
    "results.itemgot(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83a861-3072-42b9-8fb1-31296cc3b0c8",
   "metadata": {},
   "source": [
    "## Example Search Results\n",
    "\n",
    "When we search with a query about marathons and records, we get highly relevant results from our headline dataset - all about sports records and running events.\n",
    "\n",
    "This demonstrates how semantic search works - finding results based on meaning, not just keywords.\n",
    "\n",
    "## Adding New Vectors\n",
    "\n",
    "The index also allows adding new vectors. When adding:\n",
    "1. We store the vectors in our VectorStorage\n",
    "2. We rebuild the index to include these new vectors\n",
    "\n",
    "In a production system, you might use more efficient approaches for updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efdfe55e-5c19-4417-9301-48f14b8a46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_headlines = fc.L(\"Dow Jumps 1,000 Points Tuesday as Markets Rebound from Recent Losses\", # Finance\n",
    "                  \"Ronald Acuña Jr. Weeks Away from Return Following Knee Surgery\", # Sports\n",
    "                  \"George Clooney Makes Broadway Debut Playing CBS News Legend Edward R. Murrow\" # Entertainment\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4ef2199-4e61-42b7-b578-f1ce8eece131",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = news_headlines.map(lambda o: gen_emb.get_embedding(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f89e8c61-d391-4133-85b9-d39931aa3f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average list size: 9.8, Max: 28\n",
      "{'built': True, 'n_clusters': 39, 'n_vectors': 383, 'avg_cluster_size': 9.820512820512821, 'min_cluster_size': 1, 'max_cluster_size': 28, 'empty_clusters': 0, 'nprobe': 10}\n"
     ]
    }
   ],
   "source": [
    "metadata = [{\"headline\": news_headlines[0], \"genre\": \"finance\"}, \n",
    "            {\"headline\": news_headlines[1], \"genre\": \"sports\"}, \n",
    "            {\"headline\": news_headlines[2], \"genre\": \"entertainment\"}]\n",
    "index.add_vectors_bulk(embeddings, metadata)\n",
    "\n",
    "stats = index.get_stats()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5745f21d-76df-42b2-a5ce-57c8bce90a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#100) ['Marathon Runner Breaks World Record','Sprinter Breaks National Record','Climber Sets New Speed Record','City Hosts Annual Marathon','Track Star Qualifies for World Championships','Skier Wins World Championship','Pole Vaulter Sets New Record','Boxer Wins Title in Stunning Knockout','Triathlete Wins National Championship','Swimmer Sets New Olympic Record','Boxer Wins Title in Final Round','Diver Sets New Depth Record','Rowing Team Wins National Title','Skier Wins Gold in World Cup','Cricket Team Secures Historic Victory','Weightlifter Sets New Personal Best','Surfer Wins World Championship','Kayaker Navigates Record-Breaking Rapids','Rugby Team Wins International Tournament','Swimmer Breaks National Record'...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(query_vector, k=100).itemgot(1).attrgot('headline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a208a0-17ff-417e-b61e-1fb9f6e05d5d",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "The IVF Index gives us fast approximate nearest-neighbor search:\n",
    "\n",
    "- **Speed**: Only search a fraction of vectors\n",
    "- **Accuracy**: Usually finds the same results as an exhaustive search\n",
    "- **Trade-offs**: Control speed vs accuracy with `nprobe`\n",
    "\n",
    "This approach scales well to larger datasets, making vector search practical for real applications.\n",
    "\n",
    "Next, see 02_gen_embeddings.ipynb to learn how we create vectors from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a21ae54-2f48-46d4-aee1-6225b282c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68056e06-693d-462d-9666-c11241114fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (minivecdb)",
   "language": "python",
   "name": "minivecdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
